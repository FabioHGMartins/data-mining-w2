{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho prático II - Classificação\n",
    "\n",
    "O objetivo deste trabalho é praticar os conceitos de aprendizado supervisionado que vimos em sala.\n",
    "\n",
    "A sua tarefa será treinar um classificador para um conjunto de dados misterioso (se eu falasses qual é o objetivo do modelo, você encontraria soluções na Internet).\n",
    "\n",
    "Baixe o arquivo [t2.tar.gz](https://drive.google.com/file/d/125plHKUzFGxHjjCiVJcTQG2bPG_zgDNV/view?usp=sharing). Descoprima este arquivo para encontrar outros quatro. Os arquivos `train_X.csv` e `train_y.csv` possuem os dados que você deve usar para treinar o modelo. O arquivo `test_X.csv` possui os objetos para os quais você deve encontrar as classes (testar o modelo). Por fim, o arquivo `test_example_y.csv` é um exemplo de como sua solução final deve ser organizada.\n",
    "\n",
    "Cada linha dos arquivos `train_X.csv` e `test_X.csv` tem 15 campos descrevendo um objeto misterioso. O campo `id` representa o identificador do objeto, sendo que este campo não deve ser considerado em seu modelo. Os atributos a serem usados no modelo são os 14 campos rotulados de de `a` até `n`. Desses atributos:\n",
    "- `b`, `d`, `f`, `g`, `h`, `i`, `j` e `n` são categóricos; e\n",
    "- `a`, `c`, `e`, `k`, `l` e `m` são numéricos.\n",
    "\n",
    "Cada linha do arquivo `train_y.csv` possui dois campos. O primeiro é o identificador de um objeto do arquivo `train_X.csv` e o segundo é a classe do respectivo objeto (0 ou 1).\n",
    "\n",
    "Seu objetivo é encontrar as classes dos objetos do arquivo `test_X.csv` e mostrar como chegou em sua solução! Os dados do arquivo de teste foram obtido a partir de uma amostra aleatório do todo. Ou seja, um modelo bem treinado, e sem _overfitting_, em `train_X.csv` e `train_y.csv` se sairá bem em `test_X.csv`.\n",
    "\n",
    "**Data de entrega:** dia 4 de julho de 2018.\n",
    "\n",
    "**Grupo:** de até 3 pessoas, mas duas pessoas do mesmo grupo no trabalho 1 não podem pertencer ao mesmo grupo nesse trabalho.\n",
    "\n",
    "**Valor:** 20% da nota do semestre.\n",
    "\n",
    "Os três seguintes pontos descrevem o que obrigatoriamente deve ser entregue, com seu respectivo valor.\n",
    "\n",
    "1 - **[10 pontos]** Este notebook com todo seu código e resultados (números, tabelas e gráficos). Você pode usar qualquer um dos métodos que estudamos ou alguma de suas variações próximas. Se estiver na dúvida se pode usar um método, basta perguntas no Piazza. Comentários e justificativas no notebook não serão considerados para sua nota.\n",
    "O notebook deve ser enviado para o email do professor.\n",
    "\n",
    "2 - **[8 pontos]** Um relatório digitado contendo: capa, introdução, metodologia, resultados, conclusão e referências. O relatório deve ter no máximo 10 páginas, com coluna simples, fonte 11, espaçamento 1.5 e margens de 2cm. A seção de metodologia deve conter uma descrição detalhada dos passos seguidos (não incluir código no relatório). A seção de resultados deve conter obrigatoriamente: uma caracterização descritiva dos dados, matriz de confusão das predições, _precision_, _recall_, _F1 score_ e acurácia. Todas as métricas de predição devem ser calculadas a partir dos arquivos de treinamento por meio de validação cruzada.\n",
    "O relatório deve ser enviado para o email do professor.\n",
    "\n",
    "3 - **[2 pontos + equivalente a lista extra pela classificação]** A sua predição final do arquivo `test_X.csv` deve ser enviada para o professor por email. O formato deve ser o mesmo do arquivo `train_y.csv`, assim como exemplificado em `test_example_y.csv` (mas repare que as classes desse último arquivo foram gerados de forma aleatória). Em outras palavras, o arquivo a ser entregue deve ter dois campos. O campo `id` é o identificador do objeto em `test_X.csv` e o campo `label` é a classe que seu modelo encontrou para o objeto em questão. A primeira linha do arquivo deve conter os nomes das colunas.\n",
    "A entrega desse arquivo é obrigatória e vale dois pontos. Além disso, o trabalho com maior _F1 score_ ganhará o equivalente a 100% de uma lista extra. O trabalho com o pior _F1 score_ não ganhará nota extra alguma. Os demais trabalhos terão nota proporcional.\n",
    "O professor se reserva o direito de anular esse quesito (nota extra) se houver indícios de má conduta durante a competição.\n",
    "\n",
    "**Kaggle:** Estou tentando criar uma competição para esse trabalho na plataforma _Kaggle_. Se eu conseguir, compartilho o _link_ com você no _Piazza_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos arquivos de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_values = pd.read_csv(\"data/train_X.csv\")\n",
    "df_train_labels = pd.read_csv(\"data/train_Y.csv\")\n",
    "ids = df_train_values[\"id\"]\n",
    "\n",
    "df_test_values = pd.read_csv(\"data/test_X.csv\")\n",
    "\n",
    "df_train_values = df_train_values.drop(columns=[\"id\"])\n",
    "df_train_labels = df_train_labels.drop(columns=[\"id\"])\n",
    "df_test_values = df_test_values.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_attributes(df,cols):\n",
    "    for char in cols:\n",
    "        df = pd.concat(\n",
    "            [df,pd.get_dummies(df[char], prefix=char)],axis=1)\n",
    "        df.drop([char],axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "cols = [\"b\", \"d\", \"f\", \"g\", \"h\", \"i\", \"j\", \"n\"]\n",
    "\n",
    "df_train_values = categorical_attributes(df_train_values,cols)\n",
    "df_test_values = categorical_attributes(df_test_values,cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_train_values, df_train_labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "n_estimators = [3000]\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Scoring done in 435.9885401725769 seconds!\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "gscv = GridSearchCV(clf, param_grid = {'n_estimators': n_estimators}, cv = i, n_jobs=-1)\n",
    "gscv.fit(x_train,y_train)\n",
    "y_pred = gscv.predict(x_test)\n",
    "end = time.time()\n",
    "\n",
    "print('Default Scoring done in ' + str(end - start) + ' seconds!')\n",
    "print(\"Accuracy: %0.2f\" % (accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Scoring done in 413.04309010505676 seconds!\n",
      "Precision: 0.63\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "gscv = GridSearchCV(clf, scoring = 'precision', param_grid = {'n_estimators': n_estimators}, cv = i, n_jobs=-1)\n",
    "gscv.fit(x_train,y_train)\n",
    "y_pred = gscv.predict(x_test)\n",
    "end = time.time()\n",
    "\n",
    "print('Precision Scoring done in ' + str(end - start) + ' seconds!')\n",
    "print(\"Precision: %0.2f\" % (precision_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Scoring done in 415.09074091911316 seconds!\n",
      "Recall: 0.73\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "gscv = GridSearchCV(clf, scoring = 'recall', param_grid = {'n_estimators': n_estimators}, cv = i, n_jobs=-1)\n",
    "gscv.fit(x_train,y_train)\n",
    "y_pred = gscv.predict(x_test)\n",
    "end = time.time()\n",
    "\n",
    "print('Recall Scoring done in ' + str(end - start) + ' seconds!')\n",
    "print(\"Recall: %0.2f\" % (recall_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scoring done in 402.0065186023712 seconds!\n",
      "F1 Scoring: 0.68\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "gscv = GridSearchCV(clf, scoring = 'f1_macro', param_grid = {'n_estimators': n_estimators}, cv = i, n_jobs=-1)\n",
    "gscv.fit(x_train,y_train)\n",
    "y_pred = gscv.predict(x_test)\n",
    "end = time.time()\n",
    "\n",
    "print('F1 Scoring done in ' + str(end - start) + ' seconds!')\n",
    "print(\"F1 Scoring: %0.2f\" % ((f1_score(y_pred, y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# cValues = np.logspace(-10, 10, 100)\n",
    "# # clf = GridSearchCV(svm.SVC(kernel = 'linear'), param_grid = {'C': cValues}, n_jobs=-1)\n",
    "# # clf.fit(x_train, y_train)\n",
    "# clf = RandomForestClassifier(n_estimators=10000, n_jobs = -1)\n",
    "# clf.fit(x_train, y_train)\n",
    "# endTraining = time.time()\n",
    "# print('Training done in ' + str(endTraining - start) + ' seconds!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# cValues = np.logspace(-10, 10, 100)\n",
    "# clf = GridSearchCV(svm.SVC(kernel = 'linear'), param_grid = {'C': cValues}, n_jobs=-1)\n",
    "# clf.fit(x_train, y_train)\n",
    "# endTraining = time.time()\n",
    "# print('Training done in ' + str(endTraining - start) + ' seconds!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_answer_labels = clf.predict(df_train_values)\n",
    "# endEvaluation = time.time()\n",
    "# print(accuracy_score(df_train_labels, df_answer_labels))\n",
    "# print('Evaluation done in ' + str(endEvaluation - endTraining) + ' seconds!')\n",
    "# # cnf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
